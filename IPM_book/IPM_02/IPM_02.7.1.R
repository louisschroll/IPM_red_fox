# Schaub & KÃ©ry (2022) Integrated Population Models
# Chapter 2 : Bayesian statistical modeling using JAGS
# ----------------------------------------------------

# Run time approx. 3 mins

library(IPMbook)

# 2.7 Using JAGS to fit simple statistical models from R: GLMs and GLMMs
# ======================================================================

# 2.7.1 Poisson generalized linear models
# ---------------------------------------

# Define imaginary counts and elevation data for 10 sites
original.elev <- c(500, 400, 700, 500, 600, 800, 1000, 900, 1000, 900)
C <- c(6, 10, 2, 7, 4, 1, 1, 2, 0, 0)     # Counts

# Look at data and produce summaries of counts (not shown)
cbind(original.elev, C)
nind <- sum(C)
mean(C); sd(C); var(C); table(C)

# ~~~~ extra code to plot the data ~~~~
# Make a plot (not shown)
plot(original.elev, C, xlab='Site elevation (m)', ylab='Asp viper count',
    cex=1.5, pch=16, frame=FALSE, las=1)
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

elev <- (original.elev - mean(original.elev)) / 1000 # Center and scale

library(jagsUI)

# Bundle data
jags.data <- list(C=C, elev=elev, n=length(C))

str(jags.data)
# List of 3
# $ C   : num [1:10] 6 10 2 7 4 1 1 2 0 0
# $ elev: num [1:10] -0.23 -0.33 -0.03 -0.23 -0.13 0.07 0.27 0.17 0.27 0.17
# $ n   : int 10

# Write JAGS model file
cat(file="model1.txt", "
model {
  # Priors and linear models
  # One set of vague priors: 'flat' normal
  alpha ~ dnorm(0, 1.0E-06)                     # log-linear intercept
  beta ~ dnorm(0, 1.0E-06)                      # log-linear slope
  # Another possible set of vague priors: suitably wide uniform
  # alpha ~ dunif(-100, 100)                    # log-linear intercept
  # beta ~ dunif(-100, 100)                     # log-linear slope
  # Likelihood for the Poisson GLM
  for (i in 1:n){
    C[i] ~ dpois(lambda[i]) # Stochastic part
    log(lambda[i]) <- alpha + beta * elev[i]    # Link function and linear pred.
    # lambda[i] <- exp(alpha + beta * elev[i])  # Same written differently
  }
  # Derived quantities
  mean.exp.count <- exp(alpha)                  # Backtransformed intercept
}
")

# Initial values
inits <- function(){list(alpha=rnorm(1, 0, 1), beta=rnorm(1, 0, 1))}

# Parameters monitored
parameters <- c("alpha", "beta", "mean.exp.count", "lambda")

# MCMC settings
ni <- 50000; nb <- 10000; nc <- 3; nt <- 10; na <- 1000

# Call JAGS from R (ART <1 min)
out1 <- jags(jags.data, inits, parameters, "model1.txt", n.iter=ni, n.burnin=nb, n.chains=nc,
    n.thin=nt, n.adapt=na, parallel=FALSE)

# Call JAGS from R (ART <1 min) and do parallel computation
out1 <- jags(jags.data, inits, parameters, "model1.txt", n.iter=ni, n.burnin=nb, n.chains=nc,
    n.thin=nt, n.adapt=na, parallel=TRUE)

# Produce an overview of the R object created by jagsUI
str(out1) # Only a small portion of total output is shown here!

# List of 24
# $ sims.list :List of 5
# ..$ alpha         : num [1:12000] -0.0859 -0.2759 0.5362 0.5113 ...
# ..$ beta          : num [1:12000] -8.13 -7.02 -6.57 -5.51 -5.05 ...
# ..$ mean.exp.count: num [1:12000] 0.918 0.759 1.709 1.667 2.062 ...
# ..$ lambda        : num [1:12000, 1:10] 5.96 3.82 7.75 5.93 6.58 ...
# ..$ deviance      : num [1:12000] 35.2 39.4 31.5 29 28.7 ...
# $ mean      :List of 5
# ..$ alpha         : num 0.623
# ..$ beta          : num -5.16
# ..$ mean.exp.count: num 1.94
# ..$ lambda        : num [1:10(1d)] 6.21 10.52 2.25 6.21 3.71 ...
# ..$ deviance      : num 30.7
# [... output truncated ...]
# $ summary   : num [1:14, 1:11] 0.623 -5.157 1.936 6.209 10.522 ...
# ..- attr(*, "dimnames")=List of 2
# .. ..$ : chr [1:14] "alpha" "beta" "mean.exp.count" "lambda[1]" ...
# .. ..$ : chr [1:11] "mean" "sd" "2.5%" "25%" ...
# $ samples   :List of 3
# ..$ : 'mcmc' num [1:4000, 1:14] -0.0859 -0.2759 0.5362 0.5113 0.7234 ...
# .. ..- attr(*, "dimnames")=List of 2
# .. .. ..$ : NULL
# .. .. ..$ : chr [1:14] "alpha" "beta" "mean.exp.count" "lambda[1]" ...
# .. ..- attr(*, "mcpar")= num [1:3] 10010 50000 10
# ..$ : 'mcmc' num [1:4000, 1:14] 0.9 1.091 0.935 0.579 0.518 ...
# .. ..- attr(*, "dimnames")=List of 2
# .. .. ..$ : NULL
# .. .. ..$ : chr [1:14] "alpha" "beta" "mean.exp.count" "lambda[1]" ...
# .. ..- attr(*, "mcpar")= num [1:3] 10010 50000 10
# ..$ : 'mcmc' num [1:4000, 1:14] 0.294 0.559 0.226 0.646 0.545 ...
# .. ..- attr(*, "dimnames")=List of 2
# .. .. ..$ : NULL
# .. .. ..$ : chr [1:14] "alpha" "beta" "mean.exp.count" "lambda[1]" ...
# .. ..- attr(*, "mcpar")= num [1:3] 10010 50000 10
# ..- attr(*, "class")= chr "mcmc.list"
# [... output truncated ...]


jagsUI::traceplot(out1, layout=c(2, 2)) # May need jagsUI::traceplot!

# ~~~~ code for Fig 2.10 ~~~~
jagsUI::traceplot(out1, c("alpha", "beta", "mean.exp.count"), layout=c(1,3))
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~

print(out1, 3)

# JAGS output for model 'model1.txt', generated by jagsUI.
# Estimates based on 3 chains of 50000 iterations, adaptation = 1000 iterations (sufficient),
#   burn-in = 10000 iterations and thin rate = 10, yielding 12000 total samples from the
#   joint posterior.
# MCMC ran for 0.081 minutes at time 2020-11-19 18:09:13.

#                 mean    sd   2.5%    50%  97.5% overlap0     f  Rhat n.eff
# alpha          0.619 0.280  0.027  0.637  1.114    FALSE 0.979 1.000 12000
# beta          -5.178 1.140 -7.531 -5.122 -3.087    FALSE 1.000 1.000 12000
# mean.exp.count 1.929 0.520  1.028  1.892  3.048    FALSE 1.000 1.000 12000
# lambda[1]      6.210 1.115  4.233  6.132  8.558    FALSE 1.000 1.000 12000
# lambda[2]     10.541 2.479  6.354 10.327 16.022    FALSE 1.000 1.000 10153
# lambda[3]      2.238 0.550  1.271  2.206  3.414    FALSE 1.000 1.000 12000
# lambda[4]      6.210 1.115  4.233  6.132  8.558    FALSE 1.000 1.000 12000
# lambda[5]      3.705 0.689  2.472  3.657  5.171    FALSE 1.000 1.000 12000
# lambda[6]      1.368 0.453  0.618  1.325  2.365    FALSE 1.000 1.000 12000
# lambda[7]      0.529 0.283  0.141  0.478  1.229    FALSE 1.000 1.000 12000
# lambda[8]      0.846 0.363  0.296  0.795  1.692    FALSE 1.000 1.000 12000
# lambda[9]      0.529 0.283  0.141  0.478  1.229    FALSE 1.000 1.000 12000
# lambda[10]     0.846 0.363  0.296  0.795  1.692    FALSE 1.000 1.000 12000
# deviance      30.633 2.044 28.661 30.021 36.144    FALSE 1.000 1.001  3355

# Successful convergence based on Rhat values (all < 1.1).
# Rhat is the potential scale reduction factor (at convergence, Rhat=1).
# For each parameter, n.eff is a crude measure of effective sample size.

# overlap0 checks if 0 falls in the parameter's 95% credible interval.
# f is the proportion of the posterior with the same sign as the mean;
# i.e., our confidence that the parameter is positive or negative.

# DIC info: (pD = var(deviance)/2)
# pD = 2.1 and DIC = 32.721
# DIC is an estimate of expected predictive error (lower is better).

# ~~~~ extra code for Figure 2.11 ~~~~
plot(out1$sims.list$alpha, out1$sims.list$beta, pch=16, cex=0.8,
    col=rgb(0,0,0,0.2), main='', xlab='alpha', ylab='beta', frame=FALSE)
abline(v=0.5, col='red')
abline(h=-6, col='red')
condition.true <- out1$sims.list$alpha < 0.5 & out1$sims.list$beta < -6
points(out1$sims.list$alpha[condition.true], out1$sims.list$beta[condition.true],
    pch=16, cex=0.8, col=rgb(1,0,0,0.4))
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

condition.true <- out1$sims.list$alpha < 0.5 & out1$sims.list$beta < -6
mean(condition.true)
# [1] 0.1786667 # Your result will be somewhat different

# Get frequentist MLEs for comparison and predict intercept on natural scale
summary(fm <- glm(C ~ elev, family='poisson'))
predict(fm, type='response', newdata=data.frame(elev=0), se=TRUE)

# [... output truncated ...]
# Coefficients:
#             Estimate Std. Error z value Pr(>|z|)
# (Intercept)   0.6787     0.2705   2.509   0.0121 *
# elev         -5.0198     1.1035  -4.549  5.4e-06 ***
# [... output truncated ...]

# $fit
#        1
# 1.971256

# $se.fit
#         1
# 0.5331537

# New data bundle with variant of data with bigger sample size
times.bigger <- 100                       # Results in sample size of 1000
newC <- rep(C, times.bigger)
newElev <- rep(elev, times.bigger)
jags.data <- list(C=newC, elev=newElev, n=length(newC))
str(jags.data)                            # This is now the big data set

# Parameters monitored
parameters <- c("alpha", "beta", "mean.exp.count")

# Call JAGS from R (ART 2 min), check convergence and summarize posteriors
out2 <- jags(jags.data, inits, parameters, "model1.txt", n.iter=ni, n.burnin=nb, n.chains=nc,
    n.thin=nt, n.adapt=na, parallel=TRUE)
print(out2, 3)

#                    mean    sd     2.5%      50%    97.5% overlap0 f  Rhat n.eff
# alpha             0.678 0.027    0.625    0.678    0.731    FALSE 1 1.000  9482
# beta             -5.021 0.111   -5.242   -5.020   -4.807    FALSE 1 1.000  7736
# mean.exp.count    1.971 0.053    1.868    1.970    2.076    FALSE 1 1.000  9912

# Get frequentist MLEs for comparison (for the 100x larger sample size)
summary(fm <- glm(newC ~ newElev, family='poisson'))
# Coefficients:
#             Estimate Std. Error z value Pr(>|z|)
# (Intercept)  0.67867    0.02705   25.09   <2e-16 ***
# newElev     -5.01976    0.11035  -45.49   <2e-16 ***

# ~~~~ extra code for Figure 2.12 ~~~~
# Make a plot of the observed date and the fitted values (= lambda)
plot(elev, C, xlab='Site elevation (m)', ylab='Asp viper count',
    cex=1.5, pch=16, axes=FALSE)
ooo <- order(elev)
lines(sort(elev), out1$mean$lambda[ooo], col = 'blue', lwd = 3)
axis(1, at=sort(unique(elev)), labels=sort(unique(original.elev)))
axis(2, las=1)
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
